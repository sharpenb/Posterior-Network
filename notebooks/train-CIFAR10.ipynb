{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory  /nfs/homedirs/charpent/uncertainty-robustness/docs/neurips_appendix_submission/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('..')\n",
    "print(\"Current Working Directory \" , os.getcwd())\n",
    "import sys\n",
    "sys.path.append(\"../\") # Add directory containing src/data to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.posterior_networks.run import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "seed_dataset=123\n",
    "directory_dataset='../data'\n",
    "dataset_name='CIFAR10'\n",
    "ood_dataset_names=['SVHN']\n",
    "unscaled_ood=True\n",
    "split=[.6, .8]\n",
    "transform_min=0.\n",
    "transform_max=255.\n",
    "\n",
    "# Architecture parameters\n",
    "seed_model=123\n",
    "directory_model='../saved_models'\n",
    "architecture='conv'\n",
    "input_dims=[32, 32, 3]\n",
    "output_dim=10\n",
    "hidden_dims=[64, 64, 64]\n",
    "kernel_dim=5\n",
    "latent_dim=6\n",
    "no_density=False\n",
    "density_type='radial_flow'\n",
    "n_density=6\n",
    "k_lipschitz=None\n",
    "budget_function='id'\n",
    "\n",
    "# Training parameters\n",
    "directory_results='../saved_results'\n",
    "max_epochs=200\n",
    "patience=10\n",
    "frequency=2\n",
    "batch_size=64\n",
    "lr=5e-4\n",
    "loss='UCE'\n",
    "training_mode='joint'\n",
    "regr=1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/staff-hdd/charpent/anaconda3/envs/posterior-network/lib/python3.6/site-packages/torch/autograd/anomaly_mode.py:70: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  warnings.warn('Anomaly Detection has been enabled. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> Val loss 2.431 | Val Acc.: 0.098\n",
      "Model saved\n",
      "Epoch 2 -> Val loss 1.874 | Val Acc.: 0.347\n",
      "Model saved\n",
      "Epoch 4 -> Val loss 1.453 | Val Acc.: 0.48\n",
      "Model saved\n",
      "Epoch 6 -> Val loss 1.428 | Val Acc.: 0.518\n",
      "Model saved\n",
      "Epoch 8 -> Val loss 1.127 | Val Acc.: 0.614\n",
      "Model saved\n",
      "Epoch 10 -> Val loss 1.168 | Val Acc.: 0.599\n",
      "Epoch 12 -> Val loss 1.038 | Val Acc.: 0.637\n",
      "Model saved\n",
      "Epoch 14 -> Val loss 1.095 | Val Acc.: 0.617\n",
      "Epoch 16 -> Val loss 0.961 | Val Acc.: 0.669\n",
      "Model saved\n",
      "Epoch 18 -> Val loss 1.082 | Val Acc.: 0.629\n",
      "Epoch 20 -> Val loss 0.975 | Val Acc.: 0.666\n",
      "Epoch 22 -> Val loss 1.024 | Val Acc.: 0.651\n",
      "Epoch 24 -> Val loss 1.013 | Val Acc.: 0.655\n",
      "Epoch 26 -> Val loss 0.897 | Val Acc.: 0.691\n",
      "Model saved\n",
      "Epoch 28 -> Val loss 0.907 | Val Acc.: 0.689\n",
      "Epoch 30 -> Val loss 0.928 | Val Acc.: 0.683\n",
      "Epoch 32 -> Val loss 1.003 | Val Acc.: 0.657\n",
      "Epoch 34 -> Val loss 0.917 | Val Acc.: 0.689\n",
      "Epoch 36 -> Val loss 0.835 | Val Acc.: 0.716\n",
      "Model saved\n",
      "Epoch 38 -> Val loss 0.895 | Val Acc.: 0.697\n",
      "Epoch 40 -> Val loss 0.828 | Val Acc.: 0.715\n",
      "Model saved\n",
      "Epoch 42 -> Val loss 1.001 | Val Acc.: 0.663\n",
      "Epoch 44 -> Val loss 0.883 | Val Acc.: 0.705\n",
      "Epoch 46 -> Val loss 0.818 | Val Acc.: 0.723\n",
      "Model saved\n",
      "Epoch 48 -> Val loss 0.799 | Val Acc.: 0.727\n",
      "Model saved\n",
      "Epoch 50 -> Val loss 0.84 | Val Acc.: 0.718\n",
      "Epoch 52 -> Val loss 0.787 | Val Acc.: 0.736\n",
      "Model saved\n",
      "Epoch 54 -> Val loss 0.858 | Val Acc.: 0.713\n",
      "Epoch 56 -> Val loss 0.786 | Val Acc.: 0.735\n",
      "Model saved\n",
      "Epoch 58 -> Val loss 0.921 | Val Acc.: 0.699\n",
      "Epoch 60 -> Val loss 0.775 | Val Acc.: 0.739\n",
      "Model saved\n",
      "Epoch 62 -> Val loss 0.753 | Val Acc.: 0.744\n",
      "Model saved\n",
      "Epoch 64 -> Val loss 0.788 | Val Acc.: 0.735\n",
      "Epoch 66 -> Val loss 0.828 | Val Acc.: 0.725\n",
      "Epoch 68 -> Val loss 0.751 | Val Acc.: 0.745\n",
      "Model saved\n",
      "Epoch 70 -> Val loss 0.76 | Val Acc.: 0.748\n",
      "Epoch 72 -> Val loss 0.783 | Val Acc.: 0.742\n",
      "Epoch 74 -> Val loss 0.734 | Val Acc.: 0.757\n",
      "Model saved\n",
      "Epoch 76 -> Val loss 0.721 | Val Acc.: 0.755\n",
      "Model saved\n",
      "Epoch 78 -> Val loss 0.737 | Val Acc.: 0.752\n",
      "Epoch 80 -> Val loss 0.758 | Val Acc.: 0.75\n",
      "Epoch 82 -> Val loss 0.796 | Val Acc.: 0.732\n",
      "Epoch 84 -> Val loss 0.737 | Val Acc.: 0.753\n",
      "Epoch 86 -> Val loss 0.727 | Val Acc.: 0.754\n",
      "Epoch 88 -> Val loss 0.729 | Val Acc.: 0.758\n",
      "Epoch 90 -> Val loss 0.715 | Val Acc.: 0.761\n",
      "Model saved\n",
      "Epoch 92 -> Val loss 0.734 | Val Acc.: 0.756\n",
      "Epoch 94 -> Val loss 0.719 | Val Acc.: 0.76\n",
      "Epoch 96 -> Val loss 0.694 | Val Acc.: 0.771\n",
      "Model saved\n",
      "Epoch 98 -> Val loss 0.736 | Val Acc.: 0.76\n",
      "Epoch 100 -> Val loss 0.752 | Val Acc.: 0.748\n",
      "Epoch 102 -> Val loss 0.846 | Val Acc.: 0.718\n",
      "Epoch 104 -> Val loss 0.701 | Val Acc.: 0.77\n",
      "Epoch 106 -> Val loss 0.718 | Val Acc.: 0.764\n",
      "Epoch 108 -> Val loss 0.726 | Val Acc.: 0.76\n",
      "Epoch 110 -> Val loss 0.693 | Val Acc.: 0.769\n",
      "Model saved\n",
      "Epoch 112 -> Val loss 0.705 | Val Acc.: 0.766\n",
      "Epoch 114 -> Val loss 0.778 | Val Acc.: 0.749\n",
      "Epoch 116 -> Val loss 0.744 | Val Acc.: 0.76\n",
      "Epoch 118 -> Val loss 0.737 | Val Acc.: 0.757\n",
      "Epoch 120 -> Val loss 0.697 | Val Acc.: 0.771\n",
      "Epoch 122 -> Val loss 0.733 | Val Acc.: 0.759\n",
      "Epoch 124 -> Val loss 0.694 | Val Acc.: 0.765\n",
      "Epoch 126 -> Val loss 0.739 | Val Acc.: 0.758\n",
      "Epoch 128 -> Val loss 0.683 | Val Acc.: 0.774\n",
      "Model saved\n",
      "Epoch 130 -> Val loss 0.735 | Val Acc.: 0.761\n",
      "Epoch 132 -> Val loss 0.751 | Val Acc.: 0.759\n",
      "Epoch 134 -> Val loss 0.707 | Val Acc.: 0.771\n",
      "Epoch 136 -> Val loss 0.69 | Val Acc.: 0.775\n",
      "Epoch 138 -> Val loss 0.726 | Val Acc.: 0.766\n",
      "Epoch 140 -> Val loss 0.695 | Val Acc.: 0.775\n",
      "Epoch 142 -> Val loss 0.697 | Val Acc.: 0.774\n",
      "Epoch 144 -> Val loss 0.694 | Val Acc.: 0.77\n",
      "Epoch 146 -> Val loss 0.682 | Val Acc.: 0.776\n",
      "Model saved\n",
      "Epoch 148 -> Val loss 0.683 | Val Acc.: 0.781\n",
      "Epoch 150 -> Val loss 0.692 | Val Acc.: 0.772\n",
      "Epoch 152 -> Val loss 0.69 | Val Acc.: 0.775\n",
      "Epoch 154 -> Val loss 0.699 | Val Acc.: 0.771\n",
      "Epoch 156 -> Val loss 0.691 | Val Acc.: 0.772\n",
      "Epoch 158 -> Val loss 0.665 | Val Acc.: 0.785\n",
      "Model saved\n",
      "Epoch 160 -> Val loss 0.676 | Val Acc.: 0.784\n",
      "Epoch 162 -> Val loss 0.753 | Val Acc.: 0.762\n",
      "Epoch 164 -> Val loss 0.66 | Val Acc.: 0.784\n",
      "Model saved\n",
      "Epoch 166 -> Val loss 0.675 | Val Acc.: 0.777\n",
      "Epoch 168 -> Val loss 0.684 | Val Acc.: 0.779\n",
      "Epoch 170 -> Val loss 0.672 | Val Acc.: 0.782\n",
      "Epoch 172 -> Val loss 0.677 | Val Acc.: 0.781\n",
      "Epoch 174 -> Val loss 0.674 | Val Acc.: 0.78\n",
      "Epoch 176 -> Val loss 0.725 | Val Acc.: 0.766\n",
      "Epoch 178 -> Val loss 0.664 | Val Acc.: 0.785\n",
      "Epoch 180 -> Val loss 0.7 | Val Acc.: 0.776\n",
      "Epoch 182 -> Val loss 0.669 | Val Acc.: 0.785\n",
      "Early Stopping.\n"
     ]
    }
   ],
   "source": [
    "results_metrics = run(# Dataset parameters\n",
    "                        seed_dataset,  # Seed to shuffle dataset. int\n",
    "                        directory_dataset,  # Path to dataset. string\n",
    "                        dataset_name,  # Dataset name. string\n",
    "                        ood_dataset_names,  # OOD dataset names.  list of strings\n",
    "                        unscaled_ood,  # If true consider also unscaled versions of ood datasets. boolean\n",
    "                        split,  # Split for train/val/test sets. list of floats\n",
    "                        transform_min,  # Minimum value for rescaling input data. float\n",
    "                        transform_max,  # Maximum value for rescaling input data. float\n",
    "\n",
    "                        # Architecture parameters\n",
    "                        seed_model,  # Seed to init model. int\n",
    "                        directory_model,  # Path to save model. string\n",
    "                        architecture,  # Encoder architecture name. string\n",
    "                        input_dims,  # Input dimension. List of ints\n",
    "                        output_dim,  # Output dimension. int\n",
    "                        hidden_dims,  # Hidden dimensions. list of ints\n",
    "                        kernel_dim,  # Input dimension. int\n",
    "                        latent_dim,  # Latent dimension. int\n",
    "                        no_density,  # Use density estimation or not. boolean\n",
    "                        density_type,  # Density type. string\n",
    "                        n_density,  # Number of density components. int\n",
    "                        k_lipschitz,  # Lipschitz constant. float or None (if no lipschitz)\n",
    "                        budget_function,  # Budget function name applied on class count. name\n",
    "\n",
    "                        # Training parameters\n",
    "                        directory_results,  # Path to save resutls. string\n",
    "                        max_epochs,  # Maximum number of epochs for training\n",
    "                        patience,  # Patience for early stopping. int\n",
    "                        frequency,  # Frequency for early stopping test. int\n",
    "                        batch_size,  # Batch size. int\n",
    "                        lr,  # Learning rate. float\n",
    "                        loss,  # Loss name. string\n",
    "                        training_mode,  # 'joint' or 'sequential' training. string\n",
    "                        regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../saved_models/model-dpn-123-CIFAR10-[0.6, 0.8]-0.0-255.0-123-conv-[32, 32, 3]-10-[64, 64, 64]-5-6-False-radial_flow-6-None-id-200-10-2-64-0.0005-UCE-joint-1e-05\n",
      "../saved_results/results-dpn-123-CIFAR10-[0.6, 0.8]-0.0-255.0-123-conv-[32, 32, 3]-10-[64, 64, 64]-5-6-False-radial_flow-6-None-id-200-10-2-64-0.0005-UCE-joint-1e-05\n"
     ]
    }
   ],
   "source": [
    "print(results_metrics['model_path'])\n",
    "print(results_metrics['result_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7815\n",
      "confidence_aleatoric 0.9511652701566718\n",
      "confidence_epistemic 0.9483045595903589\n",
      "brier_score 0.3477715262398235\n",
      "anomaly_detection_aleatoric_SVHN 0.6917458075477938\n",
      "anomaly_detection_epistemic_SVHN 0.6858745565869325\n",
      "anomaly_detection_aleatoric_SVHN_unscaled 1.0\n",
      "anomaly_detection_epistemic_SVHN_unscaled 1.0\n"
     ]
    }
   ],
   "source": [
    "no_show = ['model_path', 'result_path', 'train_losses', 'val_losses', 'test_losses', 'train_accuracies', 'val_accuracies', 'test_accuracies', 'fail_trace']\n",
    "for k, v in results_metrics.items():\n",
    "    if k not in no_show:\n",
    "        print(k, v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
